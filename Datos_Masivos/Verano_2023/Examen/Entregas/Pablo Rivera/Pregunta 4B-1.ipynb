{"cells":[{"cell_type":"markdown","metadata":{"id":"UvbYUs4P84ED"},"source":["# Pregunta 4B | Modelamiento supervisado y clasificación\n","## Integrantes: \n","##  Juan Pablo Vergara\n","##  Pablo Rivera\n","\n","Utilizando Apache Spark, las librerías de SparkML y el dataset créditos_bancarios.xlsx\n","\n","Cree un modelo de predicción de la variable “credit_risk”. Pruebe con al menos 3 algoritmos supervisados distintos, por ej, regresión logística, árboles de decisión y random forests:\n","\n","En sus resultados comente respecto de:\n","\n","* A) qué tipo de preprocesamientos fue necesario realizarle a los datos, especialmente respecto de si fue necesario balancear la data\n","\n","* B) Los resultados de su modelo tanto en muestra de training como de testing.\n","\n","* C) Cree una tabla donde se puedan comparar las métricas de recall, precisión y accuracy para ambas clases “good” y “bad” payer (pagador). Comente y justifique cual de los 3 algoritmos funcionó mejor y por qué.\n","\n","D) Realice una breve discusión de cómo se podría implementar dicho modelo en la práctica.\n","\n","La descripción de los datos proporcionada, según la tabla de códigos es:\n","\n","#### **Variables Predictoras**\n","\n","*   **status**: 1 no checking account; 2 ... < 0 DM; 3 0<= ... < 200 DM; 4 ... >= 200 DM / salary for at least 1 year \n","*   **duration**: in months\n","*   **credit_history**: 0 delay in paying off in the past; 1 critical account/other credits elsewhere; 2 no credits taken/all credits paid back duly; 3 existing credits paid back duly till now; 4 all credits at this bank paid back duly.\n","*   **purpose**: o others; 1 car (new); 2 car (used); 3 furniture/equipment; 4  radio/television; 5 domestic appliances; 6 repairs; 7 education; 8 vacation; 9 retraining; 10 business.\n","*   **amount**: in deutsche mark\n","*   **savings**: 1 unknown/no savings account; 2 ... < 100 DM ; 3 100 <= ... < 500 DM; 4 500 <= ... < 1000 DM; 5 ... >= 1000 DM\n","*   **employment_duration**: 1 unemployed ; 2 < 1 yr ; 3 1 <= ... < 4 yrs ; 4 4 <= ... < 7 yrs ; 5 >= 7 yrs\n","*   **installment_rate**: 1 >= 35; 2 25 <= ... < 35; 3 20 <= ... < 25; 4 < 20\n","*   **personal_status_sex**: 1 male : divorced/separated; 2 female : non-single or male : single; 3 male : married/widowed; 4 female : single.\n","*   **other_debtors**: 1 none; 2 co-applicant; 3 guarantor.\n","*   **present_residence**: 1 < 1 yr; 2 1 <= ... < 4 yrs ; 3 1 <= ... < 4 yrs 4 <= ... < 7 yrs; 4 >= 7 yrs\n","*   **property**: 1 unknown / no property; 2 car or other; 3 building soc. savings agr./life insurance; 4 real estate.\n","*   **age**: in years.\n","*   **other_installment_plans**: 1 bank; 2 stores; 3 none.\n","*   **housing**: 1 for free; 2 rent; 3 own.\n","*   **number_credits**: 1 1; 2 2-3; 3 4-5; 4 >= 6.\n","*   **job**: 1 unemployed/unskilled - non-resident; 2 unskilled - resident; 3 skilled employee/official; 4 manager/self-empl./highly qualif. employee.\n","*   **people_liable**: 1 3 or more; 20 to 2.\n","*   **telephone**: 1 no; 2 yes (under customer name).\n","*   **foreign_worker**: 1 yes; 0 no.\n","\n","#### **Variable Objetivo**\n","\n","*   **credit_risk**: 0 bad; 1 good"]},{"cell_type":"markdown","metadata":{"id":"COxq_X1PSNF5"},"source":["# Instalando Spark y sus pre-requisitos"]},{"cell_type":"markdown","metadata":{"id":"MZen5Y6QSROW"},"source":["Spark y sus prerequisitos no están preinstalados en GoogleColab.\n","Por lo tanto, el primer paso es instalarlos. El principal pre-requisito es java y opcional \n","hadoop."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K-mYf4h4SLzc"},"outputs":[],"source":["!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n","!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n","!pip install -q findspark"]},{"cell_type":"markdown","metadata":{"id":"7reTcLKtS3zX"},"source":["El siguiente paso es definir las variables de entorno"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_433QuPnTEzJ"},"outputs":[],"source":["import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\""]},{"cell_type":"markdown","metadata":{"id":"4z_F7dEkTJwZ"},"source":["# Configurando la Sesión y lanzando Spark"]},{"cell_type":"markdown","metadata":{"id":"NBLAJ-mxTMuY"},"source":["Podemos comenzar a utilizar spark. Creamos una SparkSession."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IKivXT10TFDu"},"outputs":[],"source":["import findspark\n","findspark.init()\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder\\\n",".master(\"local[2]\")\\\n",".appName(\"Colab\")\\\n",".config('spark.driver.memory', '10g')\\\n",".config('spark.ui.port', '4040')\\\n",".getOrCreate()"]},{"cell_type":"markdown","metadata":{"id":"f4f8OHlDV3AT"},"source":["# Cargando los datos"]},{"cell_type":"markdown","metadata":{"id":"iFaTlNpdCAVm"},"source":["Importamos pandas para poder cargar los datos de excel e iniciamos sesión en Google Drive"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":103189,"status":"ok","timestamp":1678016758678,"user":{"displayName":"Juan Vergara Pinuer","userId":"12858029076842791033"},"user_tz":180},"id":"Mtbg2sH_WKPQ","outputId":"caf49d87-a7a1-4af2-81cb-0a25236339d4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["import pandas as pd\n","from google.colab import drive \n","drive.mount('/content/gdrive')"]},{"cell_type":"markdown","metadata":{"id":"u4AGFaduCJfE"},"source":["Cargamos el dataset utilizando pandas para posteriormente crear un dataframe de spark, definiendo las variables numéricas como enteras y las variables que representan categorías como strings."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8CE7Eg--WQYm"},"outputs":[],"source":["ruta_data_set = 'gdrive/My Drive/TAREA BIG DATA/creditos_bancarios.xlsx'\n","pd_data_set = pd.read_excel(ruta_data_set, sheet_name='SouthGermanCredit', header = 0, dtype ={\"status\":str, \"duration\":int, \"credit_history\":str, \"purpose\":str, \"amount\":int, \"savings\":str, \"employment_duration\":str, \"installment_rate\":str, \"personal_status_sex\":str,\n","                                                                                               \"other_debtors\":str, \"present_residence\":str, \"property\":str, \"age\":int, \"other_installment_plans\":str, \"housing\":str, \"number_credits\":str, \"job\":str, \"people_liable\":str,\n","                                                                                               \"telephone\":str, \"foreign_worker\":str, \"credit_risk\":str})\n","spark_data_set = spark.createDataFrame(pd_data_set)"]},{"cell_type":"markdown","metadata":{"id":"PKyLFOH_ky9-"},"source":["# Exploración de Datos"]},{"cell_type":"markdown","metadata":{"id":"hk-64FTpDitO"},"source":["Como análisis inicial de los datos, el objetivo de esta explioración es comprender qué hay en el dataset y las características de las variables."]},{"cell_type":"markdown","metadata":{"id":"HpRKT-QBEKI5"},"source":["Primero observamos una muestra inicial de los datos para asegurarnos que están bien cargados."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2LGvAVwiX6Q2","executionInfo":{"status":"ok","timestamp":1678016771022,"user_tz":180,"elapsed":6348,"user":{"displayName":"Juan Vergara Pinuer","userId":"12858029076842791033"}},"outputId":"4b70283a-a6aa-40ac-b4da-ce4b7ba90b35"},"outputs":[{"output_type":"stream","name":"stdout","text":["+------+--------+--------------+-------+------+-------+-------------------+----------------+-------------------+-------------+-----------------+--------+---+-----------------------+-------+--------------+---+-------------+---------+--------------+-----------+\n","|status|duration|credit_history|purpose|amount|savings|employment_duration|installment_rate|personal_status_sex|other_debtors|present_residence|property|age|other_installment_plans|housing|number_credits|job|people_liable|telephone|foreign_worker|credit_risk|\n","+------+--------+--------------+-------+------+-------+-------------------+----------------+-------------------+-------------+-----------------+--------+---+-----------------------+-------+--------------+---+-------------+---------+--------------+-----------+\n","|     1|      18|             4|      2|  1049|      1|                  2|               4|                  2|            1|                4|       2| 21|                      3|      1|             1|  3|            2|        1|             2|          1|\n","|     1|       9|             4|      0|  2799|      1|                  3|               2|                  3|            1|                2|       1| 36|                      3|      1|             2|  3|            1|        1|             2|          1|\n","|     2|      12|             2|      9|   841|      2|                  4|               2|                  2|            1|                4|       1| 23|                      3|      1|             1|  2|            2|        1|             2|          1|\n","|     1|      12|             4|      0|  2122|      1|                  3|               3|                  3|            1|                2|       1| 39|                      3|      1|             2|  2|            1|        1|             1|          1|\n","|     1|      12|             4|      0|  2171|      1|                  3|               4|                  3|            1|                4|       2| 38|                      1|      2|             2|  2|            2|        1|             1|          1|\n","|     1|      10|             4|      0|  2241|      1|                  2|               1|                  3|            1|                3|       1| 48|                      3|      1|             2|  2|            1|        1|             1|          1|\n","|     1|       8|             4|      0|  3398|      1|                  4|               1|                  3|            1|                4|       1| 39|                      3|      2|             2|  2|            2|        1|             1|          1|\n","|     1|       6|             4|      0|  1361|      1|                  2|               2|                  3|            1|                4|       1| 40|                      3|      2|             1|  2|            1|        1|             1|          1|\n","|     4|      18|             4|      3|  1098|      1|                  1|               4|                  2|            1|                4|       3| 65|                      3|      2|             2|  1|            2|        1|             2|          1|\n","|     2|      24|             2|      3|  3758|      3|                  1|               1|                  2|            1|                4|       4| 23|                      3|      1|             1|  1|            2|        1|             2|          1|\n","+------+--------+--------------+-------+------+-------+-------------------+----------------+-------------------+-------------+-----------------+--------+---+-----------------------+-------+--------------+---+-------------+---------+--------------+-----------+\n","only showing top 10 rows\n","\n"]}],"source":["spark_data_set = spark.createDataFrame(pd_data_set)\n","spark_data_set.show(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UZ9QoEgSy7EV","executionInfo":{"status":"ok","timestamp":1678016772305,"user_tz":180,"elapsed":1309,"user":{"displayName":"Juan Vergara Pinuer","userId":"12858029076842791033"}},"outputId":"4d60d7f5-9620-47ab-84fe-e4b1f8f4666a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1000, 21)"]},"metadata":{},"execution_count":7}],"source":["spark_data_set.count(),len(spark_data_set.columns)"]},{"cell_type":"markdown","metadata":{"id":"OoKVRMjGEZIo"},"source":["El dataset contiene 1.000 filas u observaciones y 21 columnas o variables, de las cuales 20 son variables predictoras y 1 variable es la objetivo."]},{"cell_type":"markdown","metadata":{"id":"B_21dNTyEnI-"},"source":["Corroboramos que el tipo de dato corresponda a la definición entregada entre variables numéricas y categóricas:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"stMdz6wpaIwO","executionInfo":{"status":"ok","timestamp":1678016772306,"user_tz":180,"elapsed":19,"user":{"displayName":"Juan Vergara Pinuer","userId":"12858029076842791033"}},"outputId":"8ed3d565-3e2d-46f1-cd5c-ae0c03d7484c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('status', 'string'),\n"," ('duration', 'bigint'),\n"," ('credit_history', 'string'),\n"," ('purpose', 'string'),\n"," ('amount', 'bigint'),\n"," ('savings', 'string'),\n"," ('employment_duration', 'string'),\n"," ('installment_rate', 'string'),\n"," ('personal_status_sex', 'string'),\n"," ('other_debtors', 'string'),\n"," ('present_residence', 'string'),\n"," ('property', 'string'),\n"," ('age', 'bigint'),\n"," ('other_installment_plans', 'string'),\n"," ('housing', 'string'),\n"," ('number_credits', 'string'),\n"," ('job', 'string'),\n"," ('people_liable', 'string'),\n"," ('telephone', 'string'),\n"," ('foreign_worker', 'string'),\n"," ('credit_risk', 'string')]"]},"metadata":{},"execution_count":8}],"source":["spark_data_set.dtypes"]},{"cell_type":"markdown","metadata":{"id":"Y7gNq0nqHSLX"},"source":["Para observar estadística descriptiva seleccionaremos las 3 variables definidas como numéricas"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j7EDhoilpMyP","executionInfo":{"status":"ok","timestamp":1678016774230,"user_tz":180,"elapsed":1932,"user":{"displayName":"Juan Vergara Pinuer","userId":"12858029076842791033"}},"outputId":"316b219b-b720-4125-d146-5bd4709c00f7"},"outputs":[{"output_type":"stream","name":"stdout","text":["+-------+------------------+------------------+------------------+\n","|summary|          duration|            amount|               age|\n","+-------+------------------+------------------+------------------+\n","|  count|              1000|              1000|              1000|\n","|   mean|            20.903|          3271.248|            35.542|\n","| stddev|12.058814452756373|2822.7517598956506|11.352670131696735|\n","|    min|                 4|               250|                19|\n","|    25%|                12|              1364|                27|\n","|    50%|                18|              2319|                33|\n","|    75%|                24|              3972|                42|\n","|    max|                72|             18424|                75|\n","+-------+------------------+------------------+------------------+\n","\n"]}],"source":["spark_data_set.select(\"duration\", \"amount\",\"age\").summary().show()"]},{"cell_type":"markdown","metadata":{"id":"5jjTl7shHfqt"},"source":["Se puede observar que ninguna contiene valores nulos. La variable duración está entre los valores 4 y 72, que quiere decir que la duración de los créditos está entre los 4 meses y los 72 meses (6 años) y posee un promedio de duración de 20 meses con montos que van desde los 250 marcos alemanes hasta los 18.424 con un promedio de 3.271.\n","La variable edad parte en 19 años hasta los 75 años con un pronedio de 35 años.\n","\n","De lo anterior se concluye que ninguna variable presenta datos anómalos a priori."]},{"cell_type":"markdown","metadata":{"id":"I6GilbpjQ3cq"},"source":["Por otro lado, de las variables categóricas también queremos saber si existen valores perdidos:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MYpbHaJCJpc6","executionInfo":{"status":"ok","timestamp":1678016774983,"user_tz":180,"elapsed":757,"user":{"displayName":"Juan Vergara Pinuer","userId":"12858029076842791033"}},"outputId":"48261245-f2b4-430f-90b0-b9dbd4e7c130"},"outputs":[{"output_type":"stream","name":"stdout","text":["+-------+------+--------+--------------+-------+------+-------+-------------------+----------------+-------------------+-------------+-----------------+--------+----+-----------------------+-------+--------------+----+-------------+---------+--------------+-----------+\n","|summary|status|duration|credit_history|purpose|amount|savings|employment_duration|installment_rate|personal_status_sex|other_debtors|present_residence|property| age|other_installment_plans|housing|number_credits| job|people_liable|telephone|foreign_worker|credit_risk|\n","+-------+------+--------+--------------+-------+------+-------+-------------------+----------------+-------------------+-------------+-----------------+--------+----+-----------------------+-------+--------------+----+-------------+---------+--------------+-----------+\n","|  count|  1000|    1000|          1000|   1000|  1000|   1000|               1000|            1000|               1000|         1000|             1000|    1000|1000|                   1000|   1000|          1000|1000|         1000|     1000|          1000|       1000|\n","+-------+------+--------+--------------+-------+------+-------+-------------------+----------------+-------------------+-------------+-----------------+--------+----+-----------------------+-------+--------------+----+-------------+---------+--------------+-----------+\n","\n"]}],"source":["spark_data_set.summary(\"count\").show()"]},{"cell_type":"markdown","metadata":{"id":"kvnIRVsDRAV6"},"source":["Por lo que descartamos valores perdidos en el dataset."]},{"cell_type":"markdown","metadata":{"id":"YatYE7ZARIvW"},"source":["Otro aspecto importante es revisar si existe un **desbalanceo** de las clases de la variable objetivo, si existe un desbalanceo debemos usar una estrategia para resolver este desequilibrio."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XHCHmrtm0JeM","executionInfo":{"status":"ok","timestamp":1678016778740,"user_tz":180,"elapsed":3761,"user":{"displayName":"Juan Vergara Pinuer","userId":"12858029076842791033"}},"outputId":"a78c7a76-3652-4d17-8320-42c5e8f124d0"},"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------+-----+\n","|credit_risk|count|\n","+-----------+-----+\n","|          0|  300|\n","|          1|  700|\n","+-----------+-----+\n","\n"]}],"source":["spark_data_set.groupBy(\"credit_risk\").count().show()"]},{"cell_type":"markdown","metadata":{"id":"_u-YHVNIRf--"},"source":["Se puede constatar que para la clase malo existen 300 observaciones y para la clase bueno existen 700, 30% y 70% respectivamente. Por lo que tenemos que balancear la data para mejorar nuestras predicciones. Esto lo haremos en los pasos siguientes."]},{"cell_type":"markdown","metadata":{"id":"DLoRPqeWbzCT"},"source":["# Preparación de Datos"]},{"cell_type":"markdown","metadata":{"id":"NLxghvQ_QlA6"},"source":["Como primer paso debemos transformar las variables categóricas y crear una columna para vada valor distinto que exista en la característica que estamos codificando. Usaremos el método One Hot Encoding."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kiR_l5u1Rzhj"},"outputs":[],"source":["from pyspark.sql.types import IntegerType\n","from pyspark.ml.feature import OneHotEncoder"]},{"cell_type":"markdown","metadata":{"id":"CMgkrPWlYHLD"},"source":["Antes de ejecutar el método One Hot Encoding debemos cambiar las variables a int"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fPChrS85Ucxy"},"outputs":[],"source":["categoricalColumns = ['status', 'credit_history', 'purpose', 'savings', 'employment_duration', 'installment_rate', 'personal_status_sex', 'other_debtors', 'present_residence','property',\n","                      'other_installment_plans','housing','number_credits','job','people_liable','telephone','foreign_worker']\n","\n","for i in categoricalColumns:\n","  spark_data_set = spark_data_set.withColumn(i, spark_data_set[i].cast(IntegerType()))\n","\n","spark_data_set = spark_data_set.withColumn(\"credit_risk\", spark_data_set[\"credit_risk\"].cast(IntegerType()))"]},{"cell_type":"markdown","metadata":{"id":"ri3PFM4YYPlU"},"source":["Ahora ejecutamos One Hot Encoding y podemos observar nuestras variables dummy"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vhqA-TjPRIkb","executionInfo":{"status":"ok","timestamp":1678016787340,"user_tz":180,"elapsed":7723,"user":{"displayName":"Juan Vergara Pinuer","userId":"12858029076842791033"}},"outputId":"99d65b28-70d9-42f9-d69b-00d8c6b8f7fe"},"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- status: integer (nullable = true)\n"," |-- duration: long (nullable = true)\n"," |-- credit_history: integer (nullable = true)\n"," |-- purpose: integer (nullable = true)\n"," |-- amount: long (nullable = true)\n"," |-- savings: integer (nullable = true)\n"," |-- employment_duration: integer (nullable = true)\n"," |-- installment_rate: integer (nullable = true)\n"," |-- personal_status_sex: integer (nullable = true)\n"," |-- other_debtors: integer (nullable = true)\n"," |-- present_residence: integer (nullable = true)\n"," |-- property: integer (nullable = true)\n"," |-- age: long (nullable = true)\n"," |-- other_installment_plans: integer (nullable = true)\n"," |-- housing: integer (nullable = true)\n"," |-- number_credits: integer (nullable = true)\n"," |-- job: integer (nullable = true)\n"," |-- people_liable: integer (nullable = true)\n"," |-- telephone: integer (nullable = true)\n"," |-- foreign_worker: integer (nullable = true)\n"," |-- credit_risk: integer (nullable = true)\n"," |-- status_dummy: vector (nullable = true)\n"," |-- credit_history_dummy: vector (nullable = true)\n"," |-- purpose_dummy: vector (nullable = true)\n"," |-- savings_dummy: vector (nullable = true)\n"," |-- employment_duration_dummy: vector (nullable = true)\n"," |-- installment_rate_dummy: vector (nullable = true)\n"," |-- personal_status_sex_dummy: vector (nullable = true)\n"," |-- other_debtors_dummy: vector (nullable = true)\n"," |-- present_residence_dummy: vector (nullable = true)\n"," |-- property_dummy: vector (nullable = true)\n"," |-- other_installment_plans_dummy: vector (nullable = true)\n"," |-- housing_dummy: vector (nullable = true)\n"," |-- number_credits_dummy: vector (nullable = true)\n"," |-- job_dummy: vector (nullable = true)\n"," |-- people_liable_dummy: vector (nullable = true)\n"," |-- telephone_dummy: vector (nullable = true)\n"," |-- foreign_worker_dummy: vector (nullable = true)\n","\n"]}],"source":["for i in categoricalColumns:\n","  onehot = OneHotEncoder(inputCols=[i], outputCols=[i + \"_dummy\"])\n","  onehot = onehot.fit(spark_data_set)\n","  spark_data_set = onehot.transform(spark_data_set)\n","\n","spark_data_set.printSchema()"]},{"cell_type":"markdown","source":["Para los modelos de machine learning solo usaremos las variables numéricas y las variables dummy recién obtenidas, procedemos a eliminar las que no ocuparemos"],"metadata":{"id":"pibbwRKpmWQH"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"HW8zMsDFT5L0"},"outputs":[],"source":["cols = spark_data_set.columns\n","\n","for i in categoricalColumns:\n","  cols.remove(i)\n","\n","cols.remove(\"credit_risk\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CpmYkweRZ8MA","executionInfo":{"status":"ok","timestamp":1678016787342,"user_tz":180,"elapsed":32,"user":{"displayName":"Juan Vergara Pinuer","userId":"12858029076842791033"}},"outputId":"5587b7fc-f7ab-4af2-9113-b8691d1cb999"},"outputs":[{"output_type":"stream","name":"stdout","text":["['duration', 'amount', 'age', 'status_dummy', 'credit_history_dummy', 'purpose_dummy', 'savings_dummy', 'employment_duration_dummy', 'installment_rate_dummy', 'personal_status_sex_dummy', 'other_debtors_dummy', 'present_residence_dummy', 'property_dummy', 'other_installment_plans_dummy', 'housing_dummy', 'number_credits_dummy', 'job_dummy', 'people_liable_dummy', 'telephone_dummy', 'foreign_worker_dummy']\n"]}],"source":["print(cols)"]},{"cell_type":"markdown","metadata":{"id":"33mZX3ygTyID"},"source":["Ahora combinaremos todas las variables predictoras en un único vector llamado features"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pqj1Lmz2T_0I","executionInfo":{"status":"ok","timestamp":1678016788456,"user_tz":180,"elapsed":1144,"user":{"displayName":"Juan Vergara Pinuer","userId":"12858029076842791033"}},"outputId":"c444ef28-45a1-469c-ad8c-41f5ed383551"},"outputs":[{"output_type":"stream","name":"stdout","text":["+---------------------------------------------------------------------------------------------------------------------------------------+\n","|features                                                                                                                               |\n","+---------------------------------------------------------------------------------------------------------------------------------------+\n","|(70,[0,1,2,4,13,22,28,37,40,48,54,57,63,67],[18.0,1049.0,21.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                            |\n","|(70,[0,1,2,4,11,22,29,33,38,40,44,47,54,58,63,65,67],[9.0,2799.0,36.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])        |\n","|(70,[0,1,2,5,9,20,23,30,33,37,40,47,54,57,62,67],[12.0,841.0,23.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                |\n","|(70,[0,1,2,4,11,22,29,34,38,40,44,47,54,58,62,65,67,69],[12.0,2122.0,39.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n","|(70,[0,1,2,4,11,22,29,38,40,48,51,55,58,62,67,69],[12.0,2171.0,38.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])              |\n","|(70,[0,1,2,4,11,22,28,32,38,40,45,47,54,58,62,65,67,69],[10.0,2241.0,48.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n","|(70,[0,1,2,4,11,22,30,32,38,40,47,55,58,62,67,69],[8.0,3398.0,39.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])               |\n","|(70,[0,1,2,4,11,22,28,33,38,40,47,55,57,62,65,67,69],[6.0,1361.0,40.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])        |\n","|(70,[0,1,2,14,22,27,37,40,49,55,58,61,67],[18.0,1098.0,65.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                  |\n","|(70,[0,1,2,5,9,14,24,27,32,37,40,54,57,61,67],[24.0,3758.0,23.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                      |\n","|(70,[0,1,2,4,11,22,29,33,38,40,44,47,54,58,63,65,67],[11.0,3905.0,36.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])       |\n","|(70,[0,1,2,4,12,23,30,32,40,49,54,58,63,67],[30.0,6187.0,24.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                            |\n","|(70,[0,1,2,4,14,22,30,32,37,40,49,55,57,63,67],[6.0,1957.0,31.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                      |\n","|(70,[0,1,2,5,10,23,27,33,38,40,55,57],[48.0,7582.0,31.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                          |\n","|(70,[0,1,2,4,9,14,30,33,40,49,54,58,62,67],[18.0,1936.0,23.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                             |\n","|(70,[0,1,2,4,9,14,24,29,33,38,40,45,47,54,57,63,65,67],[6.0,2647.0,44.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])  |\n","|(70,[0,1,2,4,11,22,29,32,38,40,44,47,55,58,62,65,67],[11.0,3939.0,40.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])       |\n","|(70,[0,1,2,5,9,14,24,28,32,40,45,47,54,57,63,67],[18.0,3213.0,25.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])               |\n","|(70,[0,1,2,5,14,22,38,40,47,55,57,63,67],[36.0,2337.0,36.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                   |\n","|(70,[0,1,2,11,22,29,32,38,40,48,55,58,62,67],[11.0,7228.0,39.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                           |\n","+---------------------------------------------------------------------------------------------------------------------------------------+\n","only showing top 20 rows\n","\n"]}],"source":["from pyspark.ml.feature import VectorAssembler\n","\n","assembler = VectorAssembler(inputCols=cols, outputCol=\"features\")\n","\n","spark_data_set = assembler.transform(spark_data_set)\n","spark_data_set.select(\"features\").show(truncate=False)"]},{"cell_type":"markdown","metadata":{"id":"Y5d6R4QOVSZr"},"source":["Ahora escalaremos el vector feature"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uMUJDHtFVO52","executionInfo":{"status":"ok","timestamp":1678016790081,"user_tz":180,"elapsed":1628,"user":{"displayName":"Juan Vergara Pinuer","userId":"12858029076842791033"}},"outputId":"1fa4a8bb-d058-44bb-9b13-34331bfb1af2"},"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+--------------------+\n","|            features|     Scaled_features|\n","+--------------------+--------------------+\n","|(70,[0,1,2,4,13,2...|(70,[0,1,2,4,13,2...|\n","|(70,[0,1,2,4,11,2...|(70,[0,1,2,4,11,2...|\n","|(70,[0,1,2,5,9,20...|(70,[0,1,2,5,9,20...|\n","|(70,[0,1,2,4,11,2...|(70,[0,1,2,4,11,2...|\n","|(70,[0,1,2,4,11,2...|(70,[0,1,2,4,11,2...|\n","+--------------------+--------------------+\n","only showing top 5 rows\n","\n"]}],"source":["from pyspark.ml.feature import StandardScaler\n","\n","standardscaler=StandardScaler().setInputCol(\"features\").setOutputCol(\"Scaled_features\")\n","spark_data_set=standardscaler.fit(spark_data_set).transform(spark_data_set)\n","spark_data_set.select(\"features\",\"Scaled_features\").show(5)"]},{"cell_type":"markdown","metadata":{"id":"9YL6w6kEVjdW"},"source":["### Train, Test Split"]},{"cell_type":"markdown","metadata":{"id":"iqoFPlNcVmz6"},"source":["Ya que tenemos el preprocesado de los datos vamos a separar el dataset en conjunto de entrenamiento y prueba."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_hcF6dB2Vux6"},"outputs":[],"source":["train, test = spark_data_set.randomSplit([0.8, 0.2], seed=202301)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TMJaJKO1Vzho","executionInfo":{"status":"ok","timestamp":1678016793064,"user_tz":180,"elapsed":2986,"user":{"displayName":"Juan Vergara Pinuer","userId":"12858029076842791033"}},"outputId":"302ca8bd-4545-40a2-f80f-7e5bf59df15c"},"outputs":[{"output_type":"stream","name":"stdout","text":["El número de bad payers 239\n","El porcentaje de bad payers es 30.368487928843713\n"]}],"source":["dataset_size=float(train.select(\"credit_risk\").count())\n","numNegatives=train.select(\"credit_risk\").where('credit_risk == 0').count()\n","\n","per_ones=(float(numNegatives)/float(dataset_size))*100\n","numPositives=float(dataset_size-numNegatives)\n","print('El número de bad payers {}'.format(numNegatives))\n","print('El porcentaje de bad payers es {}'.format(per_ones))"]},{"cell_type":"markdown","source":["Podemos observar que el porcentaje de bad payers es del 30%, por lo que debemos balancear nuestro set de datos."],"metadata":{"id":"wHjXwIAWOL-2"}},{"cell_type":"markdown","metadata":{"id":"S8LFgu1Iaclj"},"source":["## Balanceo"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zS9IpQNWagXa","executionInfo":{"status":"ok","timestamp":1678016793065,"user_tz":180,"elapsed":29,"user":{"displayName":"Juan Vergara Pinuer","userId":"12858029076842791033"}},"outputId":"c3a3b4c6-3eaa-4ff4-edc9-1120a1949787"},"outputs":[{"output_type":"stream","name":"stdout","text":["BalancingRatio = 0.6963151207115629\n"]}],"source":["BalancingRatio= numPositives/dataset_size\n","print('BalancingRatio = {}'.format(BalancingRatio))"]},{"cell_type":"markdown","source":["Agregamos la proporción como \"classWeights\" al dataset para ser llamada en cada modelo"],"metadata":{"id":"L0yRzxKORjps"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7RtVgx0lamxc","executionInfo":{"status":"ok","timestamp":1678016793806,"user_tz":180,"elapsed":766,"user":{"displayName":"Juan Vergara Pinuer","userId":"12858029076842791033"}},"outputId":"ef8707b1-694e-47f3-f4dd-e5d735aeda17"},"outputs":[{"output_type":"stream","name":"stdout","text":["+------------------+\n","|      classWeights|\n","+------------------+\n","|0.6963151207115629|\n","|0.6963151207115629|\n","|0.6963151207115629|\n","|0.6963151207115629|\n","|0.6963151207115629|\n","+------------------+\n","only showing top 5 rows\n","\n"]}],"source":["from pyspark.sql.functions import when\n","\n","train=train.withColumn(\"classWeights\", when(train.credit_risk == 1,BalancingRatio).otherwise(1-BalancingRatio))\n","train.select(\"classWeights\").show(5)"]},{"cell_type":"markdown","source":["# Modelos de Machine Learning"],"metadata":{"id":"d2lb1hKnmyYZ"}},{"cell_type":"markdown","source":["Los modelos supervisados que usaremos son:\n","* Logistic Regression\n","* Decision Tree\n","* Gradient-Boosted Tree Classifier"],"metadata":{"id":"OokcjUbEm9iq"}},{"cell_type":"markdown","metadata":{"id":"k-E4xRWqVbun"},"source":["# Logistic Regression"]},{"cell_type":"markdown","metadata":{"id":"WuCONnRzDz_j"},"source":["El primer algoritmo que aplicaremos es Logistic Regresion. Importamos la clase para crear el Logistic Regression classifier."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nYgvbXwTa835"},"outputs":[],"source":["from pyspark.ml.classification import LogisticRegression"]},{"cell_type":"markdown","metadata":{"id":"-4khGnAeEECx"},"source":["Creamos un objeto LogisticRegression"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8KhC5WRxEDmB"},"outputs":[],"source":["lr = LogisticRegression(labelCol=\"credit_risk\", featuresCol=\"Scaled_features\",weightCol=\"classWeights\",maxIter=100)"]},{"cell_type":"markdown","metadata":{"id":"iLV6okwPENBw"},"source":["Ajustamos el modelo a los datos de entrenamiento"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rToPQrlRENz1"},"outputs":[],"source":["lr_model=lr.fit(train)"]},{"cell_type":"markdown","metadata":{"id":"xnP8eHvOEwW9"},"source":["## Evaluación"]},{"cell_type":"markdown","metadata":{"id":"6lGFU6w7EywQ"},"source":["Ya entrenado el modelo, evaluamos su efectividad. Haremos la evaluación con el dataset de train y de test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NAPGjjFkEcy8"},"outputs":[],"source":["predict_train_lr=lr_model.transform(train)\n","predict_test_lr=lr_model.transform(test)"]},{"cell_type":"code","source":["# Confusion Matrix Train\n","\n","print(\"Confusion Matrix Logistic Regression Train\")\n","predict_train_lr.groupBy('credit_risk', 'prediction').count().show()\n","\n","# Calculate the elements of the confusion matrix\n","\n","TP_train_lr = predict_train_lr.filter('prediction = 1 AND credit_risk = prediction').count()\n","FP_train_lr = predict_train_lr.filter('prediction = 1 AND credit_risk = 0').count()\n","FN_train_lr = predict_train_lr.filter('prediction = 0 AND credit_risk = 1').count()\n","TN_train_lr = predict_train_lr.filter('prediction = 0 AND credit_risk = prediction').count()\n","\n","# Accuracy measures the proportion of correct predictions\n","accuracy_train_lr = round((TN_train_lr + TP_train_lr) / (TN_train_lr + TP_train_lr + FN_train_lr + FP_train_lr),2)\n","print(\"accuracy LR:\", accuracy_train_lr)\n","\n","# Recall: Número de elementos identificados correctamente como positivos del total de positivos verdaderos\n","recall_train_lr = round(TP_train_lr / (TP_train_lr + FN_train_lr),2)\n","print(\"recall LR:\", recall_train_lr)\n","\n","recall_train_neg_lr = round(TN_train_lr / (TN_train_lr + FP_train_lr),2)\n","print(\"recall N LR:\", recall_train_neg_lr)\n","\n","# Precision: Número de elementos identificados correctamente como positivo de un total de elementos identificados como positivos.\n","precision_train_lr = round(TP_train_lr / (TP_train_lr + FP_train_lr),2)\n","print(\"precision LR:\", precision_train_lr)\n","\n","precision_train_neg_lr = round(TN_train_lr / (TN_train_lr + FN_train_lr),2)\n","print(\"precision N LR:\", precision_train_neg_lr)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LXS92Nh-URlV","executionInfo":{"status":"ok","timestamp":1678016817590,"user_tz":180,"elapsed":9370,"user":{"displayName":"Juan Vergara Pinuer","userId":"12858029076842791033"}},"outputId":"78eb58bb-45f0-4105-f7d5-ddb70d8eed47"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Confusion Matrix Logistic Regression Train\n","+-----------+----------+-----+\n","|credit_risk|prediction|count|\n","+-----------+----------+-----+\n","|          1|       0.0|    7|\n","|          0|       0.0|   85|\n","|          1|       1.0|  541|\n","|          0|       1.0|  154|\n","+-----------+----------+-----+\n","\n","accuracy LR: 0.8\n","recall LR: 0.99\n","recall N LR: 0.36\n","precision LR: 0.78\n","precision N LR: 0.92\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ehBBfaTTFjYw","executionInfo":{"status":"ok","timestamp":1678016823595,"user_tz":180,"elapsed":6026,"user":{"displayName":"Juan Vergara Pinuer","userId":"12858029076842791033"}},"outputId":"0d9a9309-24a3-437f-ab3b-6fe67104f1c8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Confusion Matrix Logistic Regression Test\n","+-----------+----------+-----+\n","|credit_risk|prediction|count|\n","+-----------+----------+-----+\n","|          1|       0.0|    5|\n","|          0|       0.0|   14|\n","|          1|       1.0|  147|\n","|          0|       1.0|   47|\n","+-----------+----------+-----+\n","\n","accuracy LR: 0.76\n","recall LR: 0.97\n","recall N LR: 0.23\n","precision LR: 0.76\n","precision N LR: 0.74\n"]}],"source":["# Confusion Matrix Test\n","\n","print(\"Confusion Matrix Logistic Regression Test\")\n","predict_test_lr.groupBy('credit_risk', 'prediction').count().show()\n","\n","# Calculate the elements of the confusion matrix\n","\n","TP_lr = predict_test_lr.filter('prediction = 1 AND credit_risk = prediction').count()\n","FP_lr = predict_test_lr.filter('prediction = 1 AND credit_risk = 0').count()\n","FN_lr = predict_test_lr.filter('prediction = 0 AND credit_risk = 1').count()\n","TN_lr = predict_test_lr.filter('prediction = 0 AND credit_risk = prediction').count()\n","\n","# Accuracy proporción de predicciones correctas\n","accuracy_lr = round((TN_lr + TP_lr) / (TN_lr + TP_lr + FN_lr + FP_lr),2)\n","print(\"accuracy LR:\", accuracy_lr)\n","\n","# Recall: Número de elementos identificados correctamente como positivos del total de positivos verdaderos\n","recall_lr = round(TP_lr / (TP_lr + FN_lr),2)\n","print(\"recall LR:\", recall_lr)\n","\n","recall_neg_lr = round(TN_lr / (TN_lr + FP_lr),2)\n","print(\"recall N LR:\", recall_neg_lr)\n","\n","# Precision: Número de elementos identificados correctamente como positivo de un total de elementos identificados como positivos.\n","precision_lr = round(TP_lr / (TP_lr + FP_lr),2)\n","print(\"precision LR:\", precision_lr)\n","\n","precision_neg_lr = round(TN_lr / (TN_lr + FN_lr),2)\n","print(\"precision N LR:\", precision_neg_lr)"]},{"cell_type":"markdown","metadata":{"id":"O7aQ3wG0Vfqv"},"source":["# Decision Tree"]},{"cell_type":"markdown","metadata":{"id":"PTZox9uzjnEC"},"source":["El segundo algoritmo que aplicaremos es Decision Tree.\n","Importamos la clase para crear el Decision Tree classifier."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3qEYbIaNd2lE"},"outputs":[],"source":["from pyspark.ml.classification import DecisionTreeClassifier"]},{"cell_type":"markdown","metadata":{"id":"SZ_b_aLFj8CO"},"source":["Creamos un objeto DecisionTreeClassifier"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pejPtz13j3tO"},"outputs":[],"source":["tree = DecisionTreeClassifier(labelCol=\"credit_risk\", featuresCol=\"Scaled_features\",weightCol=\"classWeights\")"]},{"cell_type":"markdown","metadata":{"id":"ztSUUtFukGqa"},"source":["Ajustamos el modelo a los datos de entrenamiento"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZwFcGLNnkJeC"},"outputs":[],"source":["tree_model = tree.fit(train)"]},{"cell_type":"markdown","metadata":{"id":"-GZts_Qi940u"},"source":["## Evaluación"]},{"cell_type":"markdown","metadata":{"id":"99smzmolkLSg"},"source":["Ahora que se ha entrenado el modelo, podemos evaluar qué tan efectivo es. Hacemos predicciones en el conjunto de train y  test, y lo comparamos con los valores conocidos."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZvnAc8J5kL9N"},"outputs":[],"source":["predict_train_dt = tree_model.transform(train)\n","predict_test_dt = tree_model.transform(test)"]},{"cell_type":"code","source":["# Confusion Matrix Train\n","\n","print(\"Confusion Matrix Decision Tree Train\")\n","predict_train_dt.groupBy('credit_risk', 'prediction').count().show()\n","\n","# Calculate the elements of the confusion matrix\n","\n","TP_train_dt = predict_train_dt.filter('prediction = 1 AND credit_risk = prediction').count()\n","FP_train_dt = predict_train_dt.filter('prediction = 1 AND credit_risk = 0').count()\n","FN_train_dt = predict_train_dt.filter('prediction = 0 AND credit_risk = 1').count()\n","TN_train_dt = predict_train_dt.filter('prediction = 0 AND credit_risk = prediction').count()\n","\n","# Accuracy measures the proportion of correct predictions\n","accuracy_train_dt = round((TN_train_dt + TP_train_dt) / (TN_train_dt + TP_train_dt + FN_train_dt + FP_train_dt),2)\n","print(\"accuracy DT:\", accuracy_train_dt)\n","\n","# Recall: Número de elementos identificados correctamente como positivos del total de positivos verdaderos\n","recall_train_dt = round(TP_train_dt / (TP_train_dt + FN_train_dt),2)\n","print(\"recall DT:\", recall_train_dt)\n","\n","recall_train_neg_dt = round(TN_train_dt / (TN_train_dt + FP_train_dt),2)\n","print(\"recall N DT:\", recall_train_neg_dt)\n","\n","\n","# Precision: Número de elementos identificados correctamente como positivo de un total de elementos identificados como positivos.\n","precision_train_dt = round(TP_train_dt / (TP_train_dt + FP_train_dt),2)\n","print(\"precision DT:\", precision_train_dt)\n","\n","precision_train_neg_dt = round(TN_train_dt / (TN_train_dt + FN_train_dt),2)\n","print(\"precision N DT:\", precision_train_neg_dt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bc3ya4NDTnzr","executionInfo":{"status":"ok","timestamp":1678016958061,"user_tz":180,"elapsed":5177,"user":{"displayName":"Juan Vergara Pinuer","userId":"12858029076842791033"}},"outputId":"af3b4d47-2fc2-4cd3-d03c-12b63f408dd8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Confusion Matrix Decision Tree Train\n","+-----------+----------+-----+\n","|credit_risk|prediction|count|\n","+-----------+----------+-----+\n","|          1|       0.0|    6|\n","|          0|       0.0|   65|\n","|          1|       1.0|  542|\n","|          0|       1.0|  174|\n","+-----------+----------+-----+\n","\n","accuracy DT: 0.77\n","recall DT: 0.99\n","recall N DT: 0.27\n","precision DT: 0.76\n","precision N DT: 0.92\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6P2MNYfkd2is","executionInfo":{"status":"ok","timestamp":1678016994991,"user_tz":180,"elapsed":5242,"user":{"displayName":"Juan Vergara Pinuer","userId":"12858029076842791033"}},"outputId":"31b54277-0e61-49fb-d08e-d6414c304f8d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Confusion Matrix Decision Tree Test\n","+-----------+----------+-----+\n","|credit_risk|prediction|count|\n","+-----------+----------+-----+\n","|          1|       0.0|    4|\n","|          0|       0.0|   12|\n","|          1|       1.0|  148|\n","|          0|       1.0|   49|\n","+-----------+----------+-----+\n","\n","accuracy DT: 0.75\n","recall DT: 0.97\n","recall N DT: 0.2\n","precision DT: 0.75\n","precision N DT: 0.17\n"]}],"source":["# Confusion Matrix\n","\n","print(\"Confusion Matrix Decision Tree Test\")\n","predict_test_dt.groupBy('credit_risk', 'prediction').count().show()\n","\n","# Calculate the elements of the confusion matrix\n","\n","TP_dt = predict_test_dt.filter('prediction = 1 AND credit_risk = prediction').count()\n","FP_dt = predict_test_dt.filter('prediction = 1 AND credit_risk = 0').count()\n","FN_dt = predict_test_dt.filter('prediction = 0 AND credit_risk = 1').count()\n","TN_dt = predict_test_dt.filter('prediction = 0 AND credit_risk = prediction').count()\n","\n","# Accuracy measures the proportion of correct predictions\n","accuracy_dt = round((TN_dt + TP_dt) / (TN_dt + TP_dt + FN_dt + FP_dt),2)\n","print(\"accuracy DT:\", accuracy_dt)\n","\n","# Recall: Número de elementos identificados correctamente como positivos del total de positivos verdaderos\n","recall_dt = round(TP_dt / (TP_dt + FN_dt),2)\n","print(\"recall DT:\", recall_dt)\n","\n","recall_neg_dt = round(TN_dt / (TN_dt + FP_dt),2)\n","print(\"recall N DT:\", recall_neg_dt)\n","\n","\n","# Precision: Número de elementos identificados correctamente como positivo de un total de elementos identificados como positivos.\n","precision_dt = round(TP_dt / (TP_dt + FP_dt),2)\n","print(\"precision DT:\", precision_dt)\n","\n","precision_neg_dt = round(TN_dt / (TN_train_dt + FN_dt),2)\n","print(\"precision N DT:\", precision_neg_dt)"]},{"cell_type":"markdown","metadata":{"id":"Jhz2iK9ZdWRP"},"source":["# Gradient-Boosted Tree Classifier"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ioegod1_d2bB"},"outputs":[],"source":["from pyspark.ml.classification import GBTClassifier\n","\n","gbt = GBTClassifier(featuresCol='Scaled_features', labelCol='credit_risk', maxIter=100, weightCol=\"classWeights\")\n","gbtModel = gbt.fit(train)\n","\n","predict_train_gbt = gbtModel.transform(train)\n","predict_test_gbt = gbtModel.transform(test)"]},{"cell_type":"code","source":["# Confusion Matrix Train\n","\n","print(\"Confusion Matrix Train\")\n","predict_train_gbt.groupBy('credit_risk', 'prediction').count().show()\n","\n","# Calculate the elements of the confusion matrix\n","\n","TP_train_gbt = predict_train_gbt.filter('prediction = 1 AND credit_risk = prediction').count()\n","FP_train_gbt = predict_train_gbt.filter('prediction = 1 AND credit_risk = 0').count()\n","FN_train_gbt = predict_train_gbt.filter('prediction = 0 AND credit_risk = 1').count()\n","TN_train_gbt = predict_train_gbt.filter('prediction = 0 AND credit_risk = prediction').count()\n","\n","# Accuracy measures the proportion of correct predictions\n","accuracy_train_gbt = round((TN_train_gbt + TP_train_gbt) / (TN_train_gbt + TP_train_gbt + FN_train_gbt + FP_train_gbt),2)\n","print(\"accuracy GBT:\", accuracy_train_gbt)\n","\n","# Recall: Número de elementos identificados correctamente como positivos del total de positivos verdaderos\n","recall_train_gbt = round(TP_train_gbt / (TP_train_gbt + FN_train_gbt),2)\n","print(\"recall GBT:\", recall_train_gbt)\n","\n","recall_train_neg_gbt = round(TN_train_gbt / (TN_train_gbt + FP_train_gbt),2)\n","print(\"recall N GBT:\", recall_train_neg_gbt)\n","\n","\n","# Precision: Número de elementos identificados correctamente como positivo de un total de elementos identificados como positivos.\n","precision_train_gbt = round(TP_train_gbt / (TP_train_gbt + FP_train_gbt),2)\n","print(\"precision GBT:\", precision_train_gbt)\n","\n","precision_train_neg_gbt = round(TN_train_gbt / (TN_train_gbt + FN_train_gbt),2)\n","print(\"precision N GBT:\", precision_train_neg_gbt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uOp7IUcKhOJo","executionInfo":{"status":"ok","timestamp":1678017075004,"user_tz":180,"elapsed":9442,"user":{"displayName":"Juan Vergara Pinuer","userId":"12858029076842791033"}},"outputId":"aecc5dd8-227b-430b-9821-9241d2d1d0dd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Confusion Matrix Train\n","+-----------+----------+-----+\n","|credit_risk|prediction|count|\n","+-----------+----------+-----+\n","|          0|       0.0|  223|\n","|          1|       1.0|  548|\n","|          0|       1.0|   16|\n","+-----------+----------+-----+\n","\n","accuracy GBT: 0.98\n","recall GBT: 1.0\n","recall N GBT: 0.93\n","precision GBT: 0.97\n","precision N GBT: 1.0\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bo7ibTTbd2XM","executionInfo":{"status":"ok","timestamp":1678017117481,"user_tz":180,"elapsed":8333,"user":{"displayName":"Juan Vergara Pinuer","userId":"12858029076842791033"}},"outputId":"b249b479-9902-4241-fed2-143e2964e887"},"outputs":[{"output_type":"stream","name":"stdout","text":["Confusion Matrix Test\n","+-----------+----------+-----+\n","|credit_risk|prediction|count|\n","+-----------+----------+-----+\n","|          1|       0.0|   15|\n","|          0|       0.0|   32|\n","|          1|       1.0|  137|\n","|          0|       1.0|   29|\n","+-----------+----------+-----+\n","\n","accuracy GBT: 0.79\n","recall GBT: 0.9\n","recall N GBT: 0.52\n","precision GBT: 0.83\n","precision N GBT: 0.68\n"]}],"source":["# Confusion Matrix test\n","\n","print(\"Confusion Matrix Test\")\n","predict_test_gbt.groupBy('credit_risk', 'prediction').count().show()\n","\n","# Calculate the elements of the confusion matrix\n","\n","TP_gbt = predict_test_gbt.filter('prediction = 1 AND credit_risk = prediction').count()\n","FP_gbt = predict_test_gbt.filter('prediction = 1 AND credit_risk = 0').count()\n","FN_gbt = predict_test_gbt.filter('prediction = 0 AND credit_risk = 1').count()\n","TN_gbt = predict_test_gbt.filter('prediction = 0 AND credit_risk = prediction').count()\n","\n","# Accuracy measures the proportion of correct predictions\n","accuracy_gbt = round((TN_gbt + TP_gbt) / (TN_gbt + TP_gbt + FN_gbt + FP_gbt),2)\n","print(\"accuracy GBT:\", accuracy_gbt)\n","\n","# Recall: Número de elementos identificados correctamente como positivos del total de positivos verdaderos\n","recall_gbt = round(TP_gbt / (TP_gbt + FN_gbt),2)\n","print(\"recall GBT:\", recall_gbt)\n","\n","recall_neg_gbt = round(TN_gbt / (TN_gbt + FP_gbt),2)\n","print(\"recall N GBT:\", recall_neg_gbt)\n","\n","\n","# Precision: Número de elementos identificados correctamente como positivo de un total de elementos identificados como positivos.\n","precision_gbt = round(TP_gbt / (TP_gbt + FP_gbt),2)\n","print(\"precision GBT:\", precision_gbt)\n","\n","precision_neg_gbt = round(TN_gbt / (TN_gbt + FN_gbt),2)\n","print(\"precision N GBT:\", precision_neg_gbt)"]},{"cell_type":"markdown","metadata":{"id":"_KofFyv_dECH"},"source":["## Desarrollo"]},{"cell_type":"markdown","metadata":{"id":"ZKu1HA25sZVU"},"source":["A) Qué tipo de preprocesamientos fue necesario realizarle a los datos, especialmente respecto de si fue necesario balancear la data"]},{"cell_type":"markdown","metadata":{"id":"o-k-XnD5qKw3"},"source":["- En la fase de preprocesamiento lo que se realizó fue un One-hot encoding dado que teníamos variables categóricas, esto fue para entregar un formato de variables adecuado a los modelos de machine learning ejecutados.\n","\n","- Como pudimos observar en la data entregada es que en la variable objetivo \"credit risk\" existía un desbalance donde 300 observaciones pertenecían a la clase \"bad\" y para la clase \"good\" pertenecían 700 observaciones. Por lo que los datos de \"bad\" eran más pequeños en comparación a los \"good\" afectando la calidad de los modelos que construimos. Para subsanar este desbalance se decidió ejecutar los siguientes pasos:\n","\n","\n","1.   **Calcular la relación**, calculando la relación de la clase \"bad\" del total de observaciones\n","2.   **Calcular el peso**, posteriormente calculamos el peso de cada etiqueta.\n","3.   **Agregar columna de peso a DataFrame**, agregamos la columna calculada al DF.\n","4.   Habilitar la columna de peso en el algoritmo, agregándola a cada modelo ejecutado."]},{"cell_type":"markdown","metadata":{"id":"q8X09T0jvrgm"},"source":["B) Los resultados de su modelo tanto en muestra de training como de testing."]},{"cell_type":"markdown","source":["Para ver los resultados examinaremos las matrices de confusión tanto para la muestra de entrenamiento como de testeo."],"metadata":{"id":"gg4kenQGsi6F"}},{"cell_type":"markdown","source":["1. Logistic Regression"],"metadata":{"id":"wMyU8BRlo3s7"}},{"cell_type":"code","source":["# Confusion Matrix Train\n","print(\"Confusion Matrix Logistic Regression Train\")\n","predict_train_lr.groupBy('credit_risk', 'prediction').count().show()\n","\n","# Confusion Matrix Test\n","print(\"Confusion Matrix Logistic Regression Test\")\n","predict_test_lr.groupBy('credit_risk', 'prediction').count().show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"StkoTDMktbw9","executionInfo":{"status":"ok","timestamp":1678016916725,"user_tz":180,"elapsed":4364,"user":{"displayName":"Juan Vergara Pinuer","userId":"12858029076842791033"}},"outputId":"b19abdc5-9fd6-4b72-ca20-aa4be8174e12"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Confusion Matrix Logistic Regression Train\n","+-----------+----------+-----+\n","|credit_risk|prediction|count|\n","+-----------+----------+-----+\n","|          1|       0.0|    7|\n","|          0|       0.0|   85|\n","|          1|       1.0|  541|\n","|          0|       1.0|  154|\n","+-----------+----------+-----+\n","\n","Confusion Matrix Logistic Regression Test\n","+-----------+----------+-----+\n","|credit_risk|prediction|count|\n","+-----------+----------+-----+\n","|          1|       0.0|    5|\n","|          0|       0.0|   14|\n","|          1|       1.0|  147|\n","|          0|       1.0|   47|\n","+-----------+----------+-----+\n","\n"]}]},{"cell_type":"markdown","source":["Se puede observar que para la muestra train el modelo logistic regression hace 626 predicciones correctas de un total de 787 (80%). Mientras que para el conjunto de test logra 161 predicciones correctas de un total de 213 (76%). "],"metadata":{"id":"kV3tp5qvnZiq"}},{"cell_type":"markdown","source":["2. Decision Tree"],"metadata":{"id":"EFreCL3Zo6Ra"}},{"cell_type":"code","source":["# Confusion Matrix Train\n","print(\"Confusion Matrix Decision Tree Train\")\n","predict_train_dt.groupBy('credit_risk', 'prediction').count().show()\n","\n","# Confusion Matrix Test\n","print(\"Confusion Matrix Decision Tree Test\")\n","predict_test_dt.groupBy('credit_risk', 'prediction').count().show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YLAfFrDAtzeO","executionInfo":{"status":"ok","timestamp":1678016923802,"user_tz":180,"elapsed":7084,"user":{"displayName":"Juan Vergara Pinuer","userId":"12858029076842791033"}},"outputId":"a137dfad-dfd9-4713-962d-9a63fe33fb48"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Confusion Matrix Decision Tree Train\n","+-----------+----------+-----+\n","|credit_risk|prediction|count|\n","+-----------+----------+-----+\n","|          1|       0.0|    6|\n","|          0|       0.0|   65|\n","|          1|       1.0|  542|\n","|          0|       1.0|  174|\n","+-----------+----------+-----+\n","\n","Confusion Matrix Decision Tree Test\n","+-----------+----------+-----+\n","|credit_risk|prediction|count|\n","+-----------+----------+-----+\n","|          1|       0.0|    4|\n","|          0|       0.0|   12|\n","|          1|       1.0|  148|\n","|          0|       1.0|   49|\n","+-----------+----------+-----+\n","\n"]}]},{"cell_type":"markdown","source":["Para este segundo caso se puede observar que para la muestra train el modelo decision tree hace 607 predicciones correctas de un total de 787 (77%). Mientras que para el conjunto de test logra 160 predicciones correctas de un total de 213 (75%). Los resultados son muy parecidos a los anteriores en la muestra de test."],"metadata":{"id":"FAQHC3r1oTLn"}},{"cell_type":"markdown","source":["3. Gradient-Boosted Tree Classifier"],"metadata":{"id":"xGGK_c7lo7vA"}},{"cell_type":"code","source":["# Confusion Matrix Train\n","print(\"Confusion Matrix Train\")\n","predict_train_gbt.groupBy('credit_risk', 'prediction').count().show()\n","\n","# Confusion Matrix test\n","print(\"Confusion Matrix Test\")\n","predict_test_gbt.groupBy('credit_risk', 'prediction').count().show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AVgXsklruLIc","executionInfo":{"status":"ok","timestamp":1678016934751,"user_tz":180,"elapsed":10956,"user":{"displayName":"Juan Vergara Pinuer","userId":"12858029076842791033"}},"outputId":"44ddec68-f2a3-459b-98f0-e4d4cd90d446"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Confusion Matrix Train\n","+-----------+----------+-----+\n","|credit_risk|prediction|count|\n","+-----------+----------+-----+\n","|          0|       0.0|  223|\n","|          1|       1.0|  548|\n","|          0|       1.0|   16|\n","+-----------+----------+-----+\n","\n","Confusion Matrix Test\n","+-----------+----------+-----+\n","|credit_risk|prediction|count|\n","+-----------+----------+-----+\n","|          1|       0.0|   15|\n","|          0|       0.0|   32|\n","|          1|       1.0|  137|\n","|          0|       1.0|   29|\n","+-----------+----------+-----+\n","\n"]}]},{"cell_type":"markdown","source":["Para este tercer modelo se puede observar que para la muestra train el modelo Gradient-Boosted Tree Classifier hace 771 predicciones correctas de un total de 787 (98%). Mientras que para el conjunto de test logra 169 predicciones correctas de un total de 213 (79%). Por sobre los dos modelos anteriores."],"metadata":{"id":"Li2k-SOXosge"}},{"cell_type":"markdown","source":["C) Cree una tabla donde se puedan comparar las métricas de recall, precisión y accuracy para ambas clases “good” y “bad” payer (pagador). Comente y justifique cual de los 3 algoritmos funcionó mejor y por qué."],"metadata":{"id":"9Bp-ixr-o2SE"}},{"cell_type":"code","source":["print(\"Accuracy\")\n","print(\"----------------------------------------------------------\")\n","print(\"Logistic Regression: \",accuracy_lr)\n","print(\"Decision Tree: \",accuracy_dt)\n","print(\"Gradient-Boosted Tree Classifier: \",accuracy_gbt)\n","\n","print(\"\")\n","\n","print(\"Recall good payer\")\n","print(\"----------------------------------------------------------\")\n","print(\"Recall Logistic Regression:\", recall_lr)\n","print(\"Recall Decision Tree:\", recall_dt)\n","print(\"Recall Gradient-Boosted Tree Classifier:\", recall_gbt)\n","\n","print(\"\")\n","\n","print(\"Recall bad payer\")\n","print(\"----------------------------------------------------------\")\n","print(\"Recall Neg Logistic Regression:\", recall_neg_lr)\n","print(\"Recall Neg Decision Tree:\", recall_neg_dt)\n","print(\"Recall Neg Gradient-Boosted Tree Classifier:\", recall_neg_gbt)\n","\n","print(\"\")\n","\n","print(\"Precision good payer\")\n","print(\"----------------------------------------------------------\")\n","print(\"Precision Logistic Regression:\", precision_lr)\n","print(\"Precision Decision Tree:\", precision_dt)\n","print(\"Precision Gradient-Boosted Tree Classifier:\", precision_gbt)\n","\n","print(\"\")\n","\n","print(\"Precision bad payer\")\n","print(\"----------------------------------------------------------\")\n","print(\"Precision Neg Logistic Regression:\", precision_neg_lr)\n","print(\"Precision Neg Decision Tree:\", precision_neg_dt)\n","print(\"Precision Neg Gradient-Boosted Tree Classifier:\", precision_neg_gbt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hz2Yo9YX2as5","executionInfo":{"status":"ok","timestamp":1678018113693,"user_tz":180,"elapsed":253,"user":{"displayName":"Juan Vergara Pinuer","userId":"12858029076842791033"}},"outputId":"fe1af4e6-1ebc-4adc-cef8-d9b8edeb798f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy\n","----------------------------------------------------------\n","Logistic Regression:  0.76\n","Decision Tree:  0.75\n","Gradient-Boosted Tree Classifier:  0.79\n","\n","Recall good payer\n","----------------------------------------------------------\n","Recall Logistic Regression: 0.97\n","Recall Decision Tree: 0.97\n","Recall Gradient-Boosted Tree Classifier: 0.9\n","\n","Recall bad payer\n","----------------------------------------------------------\n","Recall Neg Logistic Regression: 0.23\n","Recall Neg Decision Tree: 0.2\n","Recall Neg Gradient-Boosted Tree Classifier: 0.52\n","\n","Precision good payer\n","----------------------------------------------------------\n","Precision Logistic Regression: 0.76\n","Precision Decision Tree: 0.75\n","Precision Gradient-Boosted Tree Classifier: 0.83\n","\n","Precision bad payer\n","----------------------------------------------------------\n","Precision Neg Logistic Regression: 0.74\n","Precision Neg Decision Tree: 0.17\n","Precision Neg Gradient-Boosted Tree Classifier: 0.68\n"]}]},{"cell_type":"markdown","source":["* Si observamos el accuracy de los modelos podemos verificar que todos se sitúan por sobre el 75% de exactitud llegando a 79% el modelo de Gradient-Booested Tree Classifier. Si miramos el recall, el modelo que menos identifica los good players es este último, sin embargo para los bad players dobla a los otros dos modelos (Logistic Regression y Decision Tree). Por último, si observamos el precision, la calidad para good payer es superior para el modelo de Gradient-Boosted Decision Tree y segundo para los bad payer, superado solo por la Logistc Regression. De lo anterior se desprende que el modelo Gradient-Boosted Tree Classifier es el mejor modelo para predecir los bad y good payers.\n","* Este resultado se debe a que un modelo Gradient-Boosted está formado por un conjunto de árboles de decisión individuales, entrenados de forma secuencial, por lo que cada nuevo árbol trata de mejorar los errores de los árboles anteriores, es por eso que los resultados son mejores a los de Decision Tree. Además son capaces de seleccionar predictores de forma automática por lo que deja fuera variables no significativas o con bajo poder explicativo. Por último, mencionar que poseen una buena escalabilidad pudiendo aplicarse a conjuntos de datos con un elevado número de observaciones como es el caso de Big Data."],"metadata":{"id":"WvhjtvC2rmok"}},{"cell_type":"markdown","metadata":{"id":"miyoWhYKGwyv"},"source":["D) Realice una breve discusión de cómo se podría implementar dicho modelo en la práctica."]},{"cell_type":"markdown","metadata":{"id":"xGIsLTCuGyLX"},"source":["Primero, la entidad que otorga los créditos debe tener un sistema que capture los datos propios del préstamo así como información del cliente, por ejemplo: la duración del crédito, el propósito, el monto del crédito, antigüedad laboral.\n","Así como información externa a la entidad, como deuda total o cuánto es su ratio de inversión en total en el sistema bancario.\n","\n","Respecto al modelo de machine learning, para pasar de una etapa de desarrollo a una etapa de producción podríamos usar Databricks que posee una plataforma MLOps que proporciona un entorno de gestión de modelos junta a otras capacidades como exploración iterativa de datos, gestión de modelos, etc.\n","\n","Especificamente:\n","\n","* Seguimiento: Registro y consulta de experimentos\n","* Proyectos: Formato de empaquetado para reproducir modelos\n","* Modelos: formato general de modelos para portabilidad y despliegues flexibles\n","* Registro: Gestión del ciclo de vida de los modelos"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}